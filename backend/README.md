# BSSOD Analyzer Backend API

FastAPI backend for processing memory dump analysis and AI integration.

## ğŸ¯ Purpose

This API receives ZIP exports from the Parser Tool and provides AI-powered crash analysis using Claude 4 Sonnet via Trend Micro's endpoint.

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install -r requirements.txt

# Start the server
python -m uvicorn src.main:app --host 127.0.0.1 --port 8080

# Or with auto-reload for development
python -m uvicorn src.main:app --host 127.0.0.1 --port 8080 --reload
```

## ğŸ“¡ API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API info and documentation links |
| GET | `/api/v1/health` | Health check |
| POST | `/api/v1/analyze` | Upload ZIP file for AI analysis |

### POST /api/v1/analyze

Upload a ZIP file exported from the Parser Tool.

**Request:**
- Content-Type: `multipart/form-data`
- Body: `file` - ZIP file containing `analysis.json`

**Response:**
```json
{
  "success": true,
  "message": "Analysis completed successfully",
  "dump_file": "MEMORY.DMP",
  "bugcheck_code": "0x0000001A",
  "bugcheck_name": "MEMORY_MANAGEMENT",
  "ai_analysis": {
    "analysis": "Full AI analysis text...",
    "model": "claude-4-sonnet",
    "tokens_used": 1234
  }
}
```

## ğŸ”§ Configuration

Create a `.env` file in the `backend` directory or project root:

```env
# AI Configuration (Required)
OPENAI_BASE_URL=https://api.rdsec.trendmicro.com/prod/aiendpoint/v1/
OPENAI_API_KEY=your-api-key
OPENAI_MODEL=claude-4-sonnet
AI_TIMEOUT=120.0

# Server Configuration
HOST=0.0.0.0
PORT=8080
DEBUG=false

# CORS
CORS_ORIGINS=http://localhost:3000

# Upload limits
MAX_UPLOAD_SIZE_MB=50
```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py           # API endpoints
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ai_service.py       # AI API integration
â”‚   â”‚   â”œâ”€â”€ prompt_engineering.py # AI prompt formatting
â”‚   â”‚   â””â”€â”€ zip_validator.py    # ZIP validation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â””â”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_backend.py         # Unit tests
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ .env.example                # Example configuration
â””â”€â”€ requirements.txt            # Python dependencies
```

## ğŸ§ª Testing

```bash
# Run all tests
python -m pytest tests/ -v

# Run with coverage
python -m pytest tests/ -v --cov=src
```

**Current Test Status:** 10/10 passing âœ…

## ğŸ“‹ Dependencies

- **FastAPI** - Web framework
- **Uvicorn** - ASGI server
- **Pydantic** - Data validation
- **httpx** - Async HTTP client
- **python-dotenv** - Environment variables
- **python-multipart** - File uploads
- **pytest** - Testing

## ğŸ”’ Security

- API key stored in environment variables (never in code)
- File size limits enforced
- ZIP content validation
- CORS configuration for frontend

## âš ï¸ Limitations

- Maximum file upload: 50 MB (configurable)
- AI response timeout: 120 seconds (configurable)
- Session-only approach (no database persistence)

## ğŸ“Š Module Line Counts

| File | Lines | Status |
|------|-------|--------|
| config.py | 86 | âœ… |
| main.py | 58 | âœ… |
| routes.py | 117 | âœ… |
| schemas.py | 157 | âœ… |
| ai_service.py | 167 | âœ… |
| prompt_engineering.py | 225 | âœ… |
| zip_validator.py | 134 | âœ… |

All modules under 500 lines âœ…

---

See the [main project README](../README.md) for full project documentation.
